# Face-Recognition-using-workload-generator-AWS-Lambda-and-AWS-DynamoDB

Architecture
![image](https://user-images.githubusercontent.com/38141800/200203197-e0aefc4a-304a-4e65-b93b-82ab0009f523.png)

AWS Services used in the project
AWS Lambda: 
You may run code for practically any kind of application or backend service with AWS Lambda, a serverless, event-driven computing service, without creating or managing servers. Our complete code is performed using AWS Lambda as a PaaS, and it then returns the appropriate academic data to the output bucket. The creation of the Input Bucket object is the sole event that sets off the Lambda function.

AWS S3:
We are using AWS S3 to store input videos (.mp4) that were uploaded to the input bucket by the task generator. After the picture recognition is finished, the Lambda function stores the student's academic data (.csv) in the output bucket so that the user can examine it. For persistence, we use the AWS S3 service.

AWS ECR:
You can deploy, maintain, and grow containerized apps with ease using Amazon ECR, a fully managed container orchestration service. We are utilizing this service to store the Docker image that will be used to launch the AWS Lambda service.

Amazon DynamoDB:
Amazon DynamoDB is a fully managed, serverless, key-value NoSQL database
designed to run high-performance applications at any scale. We are utilizing Amazon DynamoDB to store the academic information of the person in a key-value format.

Amazon Cloudwatch:
This service that is provided by AWS helps keep an eye on the logs generated by
different AWS services. We used this service while developing the lambda function to understand the different intermediary results and their types.

Architecture Explanation
In our architecture, we have two AWS S3 buckets for storing input and output data and a single AWS Lambda function to perform image recognition on the frames of movies delivered to the system and return related data saved in Amazon DynamoDB. Videos make up the input data, while academic knowledge makes up the output data. A Docker image containing the software and packages needed to run the AWS Lambda function serves as its foundation. Locally created and kept in an ECR repository, this image. This lambda function is activated with information pertaining to the file that was dropped once a video is dropped into the input S3 bucket. The function uses this data to download the movie to the lambda environment, extract image frames from it, classify the image using the face_recognition python package, and search for the resulting name in our DynamoDB. The academic details of the person identified in the video were taken from the database. This is transferred to the output S3 bucket in.csv format for storage. Finally, before exiting, the intermediary files created by the function are deleted since their
persistence is not necessary.

Code

1. handler.py:
This python file contains the code for the AWS Lambda function whose functionality is to
download the input video to the ~/tmp folder, extract a frame from the video, perform
facial recognition using the provided model, request the academic information from
DynamoDB, upload the information to the output bucket and finally delete all the files
stored in ~/tmp folder.

2. Dockerfile:
The Docker file contains the script to install the packages required for the code to run
The image built on this file is used by the AWS Lambda function to perform the
functionalities.

3. student_data.json:
This file contains the academic records data of different individuals. This is used to
prepopulate the database that is then later queried.

4. encoding: 
This file contains the trained deep learning model which the handler.py imports to classify the images extracted from the input video. 

5. entry.sh: 
This shell script is used to invoke the “handler.face_recognition_handler” function in the lambda environment when it is triggered. 

How to run:

1. Install Python.
2. Install boto3 and awscli packages and configure the AWS environment.
3. Open the workload.py file and change the input and output bucket variables to point to
the correct values as mentioned above.
4. Execute the workload file to upload videos to the input bucket. This triggers the lambda
function to execute.
5. Open the output bucket on the browser to find the respective academic records being
generated.

